# ==========================================
# Quickstart ‚Äî Ollama Local LLM
# Teste r√°pido de embeddings + chat
# ==========================================

Write-Host "ü¶ô Ollama Quickstart - Local LLM Testing" -ForegroundColor Cyan
Write-Host "========================================" -ForegroundColor Cyan
Write-Host ""

# 1. Verificar se Ollama est√° rodando
Write-Host "1Ô∏è‚É£  Verificando Ollama..." -ForegroundColor Yellow
try {
    $health = Invoke-RestMethod -Uri "http://localhost:11434/api/tags" -Method Get -ErrorAction Stop
    Write-Host "‚úÖ Ollama est√° online!" -ForegroundColor Green
    Write-Host ""
} catch {
    Write-Host "‚ùå Ollama n√£o est√° rodando. Iniciando..." -ForegroundColor Red
    Write-Host ""
    Write-Host "Executando: docker-compose -f docker-compose.pathway.yml up -d ollama" -ForegroundColor Gray
    docker-compose -f docker-compose.pathway.yml up -d ollama
    
    Write-Host "‚è≥ Aguardando Ollama iniciar (60s)..." -ForegroundColor Yellow
    Start-Sleep -Seconds 60
    
    try {
        $health = Invoke-RestMethod -Uri "http://localhost:11434/api/tags" -Method Get -ErrorAction Stop
        Write-Host "‚úÖ Ollama iniciado com sucesso!" -ForegroundColor Green
        Write-Host ""
    } catch {
        Write-Host "‚ùå Erro ao iniciar Ollama. Verifique logs: docker logs ysh-ollama" -ForegroundColor Red
        exit 1
    }
}

# 2. Listar modelos dispon√≠veis
Write-Host "2Ô∏è‚É£  Modelos instalados:" -ForegroundColor Yellow
try {
    $models = Invoke-RestMethod -Uri "http://localhost:11434/api/tags" -Method Get -ErrorAction Stop
    foreach ($model in $models.models) {
        $name = $model.name
        $size = [math]::Round($model.size / 1GB, 2)
        Write-Host "   üì¶ $name ($size GB)" -ForegroundColor Cyan
    }
    Write-Host ""
} catch {
    Write-Host "‚ùå Erro ao listar modelos" -ForegroundColor Red
}

# 3. Teste de Embeddings
Write-Host "3Ô∏è‚É£  Teste de Embeddings (nomic-embed-text)..." -ForegroundColor Yellow
$testText = "Painel solar monocristalino 550W alta efici√™ncia"

try {
    $embedPayload = @{
        model = "nomic-embed-text"
        prompt = $testText
    } | ConvertTo-Json

    $embedStart = Get-Date
    $embedResponse = Invoke-RestMethod -Uri "http://localhost:11434/api/embeddings" -Method Post -Body $embedPayload -ContentType "application/json" -ErrorAction Stop
    $embedEnd = Get-Date
    $embedLatency = ($embedEnd - $embedStart).TotalMilliseconds

    $embeddingDim = $embedResponse.embedding.Count
    Write-Host "   ‚úÖ Embedding gerado!" -ForegroundColor Green
    Write-Host "   üìä Dimens√µes: $embeddingDim" -ForegroundColor Cyan
    Write-Host "   ‚ö° Lat√™ncia: $([math]::Round($embedLatency, 2)) ms" -ForegroundColor Cyan
    Write-Host "   üìù Texto: '$testText'" -ForegroundColor Gray
    Write-Host ""
} catch {
    Write-Host "   ‚ùå Erro ao gerar embedding: $_" -ForegroundColor Red
    Write-Host ""
}

# 4. Teste de Chat (Qwen2.5 20B)
Write-Host "4Ô∏è‚É£  Teste de Chat (qwen2.5:20b)..." -ForegroundColor Yellow
$testPrompt = "Explique em 50 palavras o que √© irradia√ß√£o solar."

try {
    $chatPayload = @{
        model = "qwen2.5:20b"
        messages = @(
            @{
                role = "system"
                content = "Voc√™ √© H√©lio, especialista em energia solar."
            },
            @{
                role = "user"
                content = $testPrompt
            }
        )
        stream = $false
        options = @{
            temperature = 0.7
            num_predict = 100
        }
    } | ConvertTo-Json -Depth 5

    $chatStart = Get-Date
    $chatResponse = Invoke-RestMethod -Uri "http://localhost:11434/api/chat" -Method Post -Body $chatPayload -ContentType "application/json" -ErrorAction Stop
    $chatEnd = Get-Date
    $chatLatency = ($chatEnd - $chatStart).TotalMilliseconds

    $response = $chatResponse.message.content
    Write-Host "   ‚úÖ Resposta gerada!" -ForegroundColor Green
    Write-Host "   ‚ö° Lat√™ncia: $([math]::Round($chatLatency, 2)) ms" -ForegroundColor Cyan
    Write-Host "   üí¨ Pergunta: '$testPrompt'" -ForegroundColor Gray
    Write-Host "   ü§ñ Resposta:" -ForegroundColor Cyan
    Write-Host "   $response" -ForegroundColor White
    Write-Host ""
} catch {
    Write-Host "   ‚ùå Erro ao gerar chat: $_" -ForegroundColor Red
    Write-Host ""
}

# 5. Compara√ß√£o com OpenAI (se API key dispon√≠vel)
$openaiKey = $env:OPENAI_API_KEY
if ($openaiKey) {
    Write-Host "5Ô∏è‚É£  Compara√ß√£o com OpenAI..." -ForegroundColor Yellow
    
    try {
        # OpenAI Embeddings
        $openaiEmbedPayload = @{
            model = "text-embedding-3-large"
            input = $testText
        } | ConvertTo-Json

        $openaiEmbedStart = Get-Date
        $openaiEmbedResponse = Invoke-RestMethod `
            -Uri "https://api.openai.com/v1/embeddings" `
            -Method Post `
            -Headers @{
                "Authorization" = "Bearer $openaiKey"
                "Content-Type" = "application/json"
            } `
            -Body $openaiEmbedPayload `
            -ErrorAction Stop
        $openaiEmbedEnd = Get-Date
        $openaiEmbedLatency = ($openaiEmbedEnd - $openaiEmbedStart).TotalMilliseconds

        $openaiDim = $openaiEmbedResponse.data[0].embedding.Count
        
        Write-Host "   üìä OpenAI Embeddings:" -ForegroundColor Cyan
        Write-Host "      - Dimens√µes: $openaiDim" -ForegroundColor White
        Write-Host "      - Lat√™ncia: $([math]::Round($openaiEmbedLatency, 2)) ms" -ForegroundColor White
        Write-Host "      - Custo: ~`$0.00013 (1K tokens)" -ForegroundColor White
        Write-Host ""
        Write-Host "   üìä Ollama Embeddings:" -ForegroundColor Cyan
        Write-Host "      - Dimens√µes: $embeddingDim" -ForegroundColor White
        Write-Host "      - Lat√™ncia: $([math]::Round($embedLatency, 2)) ms" -ForegroundColor White
        Write-Host "      - Custo: `$0 (local)" -ForegroundColor White
        Write-Host ""
        Write-Host "   üèÜ Speedup: $([math]::Round($openaiEmbedLatency / $embedLatency, 2))x mais r√°pido (Ollama)" -ForegroundColor Green
        Write-Host ""
        
    } catch {
        Write-Host "   ‚ö†Ô∏è  N√£o foi poss√≠vel testar OpenAI: $_" -ForegroundColor Yellow
        Write-Host ""
    }
} else {
    Write-Host "5Ô∏è‚É£  Compara√ß√£o OpenAI: SKIPPED (API key n√£o configurada)" -ForegroundColor Yellow
    Write-Host "   Para habilitar: Set OPENAI_API_KEY=sk-..." -ForegroundColor Gray
    Write-Host ""
}

# 6. Resumo
Write-Host "========================================" -ForegroundColor Cyan
Write-Host "‚úÖ Quickstart conclu√≠do!" -ForegroundColor Green
Write-Host ""
Write-Host "üìö Pr√≥ximos passos:" -ForegroundColor Yellow
Write-Host "   1. Testar no Dagster UI: http://localhost:3001" -ForegroundColor White
Write-Host "      ‚Üí Assets ‚Üí example_hybrid_rag ‚Üí Materialize" -ForegroundColor Gray
Write-Host ""
Write-Host "   2. Rodar benchmark:" -ForegroundColor White
Write-Host "      ‚Üí Assets ‚Üí benchmark_llm_providers ‚Üí Materialize" -ForegroundColor Gray
Write-Host ""
Write-Host "   3. Documenta√ß√£o completa:" -ForegroundColor White
Write-Host "      ‚Üí docs/OLLAMA_LOCAL_LLM_INTEGRATION.md" -ForegroundColor Gray
Write-Host ""
Write-Host "üí∞ Economia estimada: `$1.500-2.000/ano (vs OpenAI-only)" -ForegroundColor Green
Write-Host "‚ö° Lat√™ncia reduzida: 2-4x mais r√°pido (local)" -ForegroundColor Green
Write-Host "üîí Data privacy: 100% LGPD-compliant" -ForegroundColor Green
Write-Host ""
