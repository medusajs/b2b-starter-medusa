# YSH Data Platform â€” Pathway + Dagster

> **Stack de dados real-time** para o ecossistema Yello Solar Hub (B2B e-commerce).

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Fontes de Dados                         â”‚
â”‚  Medusa â€¢ ANEEL APIs â€¢ NASA/PVGIS â€¢ Inmetro â€¢ S3/MinIO         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Pathway Streaming Engine                    â”‚
â”‚  â€¢ Kafka/Postgres CDC â€¢ S3 â€¢ HTTP                             â”‚
â”‚  â€¢ Transformations (Python) â€¢ RAG Pipeline                    â”‚
â”‚  â€¢ Sinks: Postgres, Pinecone, S3                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Dagster (Orchestration)                       â”‚
â”‚  â€¢ Assets: catalog, tarifas, propostas, embeddings            â”‚
â”‚  â€¢ Jobs: ETL batch + streaming monitors                       â”‚
â”‚  â€¢ Schedules: cron daily/hourly                               â”‚
â”‚  â€¢ UI: http://localhost:3001                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Apps & Consumers                             â”‚
â”‚  Medusa Backend â€¢ Storefront â€¢ HÃ©lio Agent (LLM+RAG)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### 1. PrÃ©-requisitos

- **Docker** e **Docker Compose** instalados
- **Python 3.11+** (para dev local)
- **VariÃ¡veis de ambiente** configuradas (ver `.env.example`)

### 2. Configurar variÃ¡veis de ambiente

Crie `.env` na raiz de `data-platform/`:

```bash
# AWS/S3
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret
AWS_REGION=us-east-1
S3_BUCKET=ysh-data-lake

# Pinecone
PINECONE_API_KEY=pk_***
PINECONE_INDEX=ysh-rag

# OpenAI
OPENAI_API_KEY=sk-***
```

### 3. Subir serviÃ§os

```powershell
# Terminal 1: Backend Medusa + Postgres + Redis (se nÃ£o estiver rodando)
cd c:\Users\fjuni\ysh_medusa\ysh-store
docker-compose up -d postgres redis

# Terminal 2: Dagster + Pathway
cd c:\Users\fjuni\ysh_medusa\ysh-store\data-platform
docker-compose -f docker-compose.dagster.yml up -d
docker-compose -f docker-compose.pathway.yml up -d
```

### 4. Acessar UIs

- **Dagster UI:** <http://localhost:3001>
- **MinIO Console:** <http://localhost:9002> (user: `minioadmin`, password: `minioadmin`)

---

## ğŸ“¦ Estrutura de CÃ³digo

```
data-platform/
â”œâ”€â”€ dagster/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ definitions.py          # Entry point Dagster
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ catalog.py          # @asset catalog_normalized, catalog_embeddings
â”‚   â”‚   â””â”€â”€ tarifas.py          # @asset tarifas_aneel
â”‚   â””â”€â”€ resources/
â”‚       â”œâ”€â”€ postgres.py         # PostgresResource
â”‚       â””â”€â”€ pinecone.py         # PineconeResource
â”œâ”€â”€ pathway/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ pipelines/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ catalog_etl.py      # ETL catÃ¡logo (batch/streaming)
â”‚       â””â”€â”€ rag_streaming.py    # RAG real-time
â”œâ”€â”€ docker-compose.dagster.yml
â”œâ”€â”€ docker-compose.pathway.yml
â””â”€â”€ README.md                   # Este arquivo
```

---

## ğŸ”§ Desenvolvimento Local

### Instalar dependÃªncias Python

```powershell
# Dagster
cd dagster
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt

# Pathway
cd ..\pathway
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

### Rodar Dagster localmente (sem Docker)

```powershell
cd dagster
$env:DAGSTER_HOME = (Get-Location).Path
dagster dev -m definitions
# Abrir http://localhost:3000
```

### Materializar um asset

```powershell
dagster asset materialize -m definitions -a catalog_normalized
```

### Rodar pipeline Pathway localmente

```powershell
cd pathway
python -m pipelines.catalog_etl
```

---

## ğŸ“Š Assets Implementados

| Asset | DescriÃ§Ã£o | Fontes | Sinks | Schedule |
|-------|-----------|--------|-------|----------|
| `catalog_normalized` | CatÃ¡logo FV normalizado | S3, Inmetro | Postgres | Daily 2h |
| `catalog_embeddings` | Embeddings do catÃ¡logo | Postgres | Pinecone | Daily 2h |
| `tarifas_aneel` | Tarifas ANEEL | APIs ANEEL | Postgres | Daily 6h |

---

## ğŸ§ª Testes

```powershell
# Unit tests (quando implementados)
pytest tests/

# Validar Dagster definitions
dagster definitions validate -m definitions
```

---

## ğŸ“š DocumentaÃ§Ã£o

- **Blueprint completo:** [../docs/PATHWAY_DAGSTER_PREFECT_BLUEPRINT.md](../docs/PATHWAY_DAGSTER_PREFECT_BLUEPRINT.md)
- **Dagster Docs:** <https://docs.dagster.io>
- **Pathway Docs:** <https://pathway.com/developers>

---

## ğŸ› Troubleshooting

### Erro: "Cannot connect to Postgres"

- Verificar se `postgres` service estÃ¡ rodando: `docker ps`
- Verificar env vars: `POSTGRES_HOST`, `POSTGRES_PORT`, etc.

### Erro: "Pinecone index not found"

- Criar Ã­ndice no [Pinecone Console](https://app.pinecone.io)
- DimensÃ£o: 3072 (para `text-embedding-3-large`)
- Metric: cosine

### Dagster UI nÃ£o carrega

- Verificar logs: `docker logs ysh-dagster-webserver`
- Verificar porta: `netstat -ano | findstr :3001`

---

## ğŸš¢ Deploy (ProduÃ§Ã£o)

Ver seÃ§Ã£o "Deploy (Roadmap)" no blueprint principal.

**OpÃ§Ãµes:**

1. **AWS ECS Fargate** (recomendado para inÃ­cio)
2. **Kubernetes (EKS/GKE)** (para escala)
3. **Dagster+** (managed service)

---

## ğŸ¤ Contribuindo

1. Criar branch: `git checkout -b feature/novo-asset`
2. Implementar asset/pipeline
3. Testar localmente
4. Abrir PR

---

## ğŸ“ Contato

- **Comandante A**
- **HÃ©lio Copiloto Solar**

---

**Status:** ğŸš§ **Em desenvolvimento** (v0.1.0 â€” estrutura inicial)

**PrÃ³ximos passos:**

- [ ] Implementar pipeline Pathway real (catalog_etl)
- [ ] Integrar OpenAI embeddings
- [ ] Configurar Pinecone upserts
- [ ] Adicionar sensors (S3 file arrivals)
- [ ] Criar asset de propostas (join quotes + tarifas)
- [ ] Deploy em AWS ECS (Fargate)
