# ü§ñ OLLAMA GPT-OSS 20B - Guia de Uso

**Modelo:** gpt-oss:20b (13 GB)  
**Status:** ‚úÖ Instalado e funcionando  
**Vers√£o Ollama:** 0.12.3  
**Endpoint:** <http://localhost:11434>

---

## üöÄ QUICK START

### 1. Testar Conex√£o

```bash
cd c:\Users\fjuni\ysh_medusa\ysh-erp\scripts
python ollama_gpt.py test
```

### 2. Chat Interativo

```bash
python ollama_gpt.py chat
```

### 3. Melhorar Descri√ß√µes de Produtos

```bash
python ollama_gpt.py enhance ../data/catalog/unified_schemas ../data/catalog/enhanced
```

---

## üìä CASOS DE USO

### 1. An√°lise de Qualidade de Produtos

```python
from ollama_gpt import OllamaGPT

client = OllamaGPT()

# Analisar produto
product = {
    "name": "Inversor Growatt MIN 3000TL-X",
    "manufacturer": "GROWATT",
    "category": "inverters",
    "description": "Inversor monof√°sico 3kW com 2 MPPT"
}

analysis = client.analyze_product(product)

print(f"Confian√ßa na categoria: {analysis['category_confidence']}")
print(f"Qualidade dos dados: {analysis['quality_score']}/10")
print(f"Melhorias sugeridas: {analysis['suggested_improvements']}")
```

**Output:**

```json
{
  "category_confidence": 0.95,
  "quality_score": 7,
  "suggested_improvements": [
    "Incluir especifica√ß√µes t√©cnicas detalhadas",
    "Adicionar informa√ß√µes sobre dimens√µes e peso",
    "Fornecer dados de certifica√ß√µes"
  ],
  "key_features": [
    "Inversor monof√°sico",
    "Pot√™ncia nominal de 3 kW",
    "Suporte a 2 MPPT"
  ]
}
```

---

### 2. Melhorar Descri√ß√µes de Produtos

```python
client = OllamaGPT()

product = {
    "name": "Painel Solar Canadian 550W",
    "description": "Painel solar 550w bifacial",
    "specifications": {
        "potencia": "550W",
        "tipo": "Bifacial",
        "eficiencia": "21.2%"
    }
}

enhanced_desc = client.enhance_description(product)
print(enhanced_desc)
```

**Output:**

```
Painel Solar Canadian 550W - M√≥dulo Fotovoltaico Bifacial de Alta Efici√™ncia

Este painel solar bifacial de 550W combina tecnologia de ponta com desempenho 
superior, oferecendo efici√™ncia de 21.2% e capacidade de captar energia solar 
em ambas as faces. Ideal para aplica√ß√µes residenciais e comerciais que buscam 
maximizar a gera√ß√£o de energia renov√°vel com menor √°rea de instala√ß√£o.

Caracter√≠sticas principais:
- Pot√™ncia nominal: 550W
- Tecnologia bifacial para at√© 30% mais gera√ß√£o
- Efici√™ncia superior: 21.2%
- Fabricante: Canadian Solar
```

---

### 3. Extra√ß√£o de Especifica√ß√µes

```python
client = OllamaGPT()

text = """
O inversor Growatt MIN 3000TL-X possui pot√™ncia de 3000W, 
tens√£o de entrada de 80-550V, 2 MPPT independentes, 
efici√™ncia m√°xima de 98.4% e dimens√µes 330x415x148mm.
Peso: 10.5kg
"""

specs = client.extract_specs(text, category="inverters")
print(specs)
```

**Output:**

```json
{
  "potenciaNominal": "3000W",
  "tensaoEntrada": "80-550V",
  "numeroMPPT": 2,
  "eficienciaMaxima": "98.4%",
  "dimensoes": "330x415x148mm",
  "peso": "10.5kg"
}
```

---

### 4. Chat Interativo com Contexto

```python
client = OllamaGPT()

context = []

# Primeira pergunta
msg1 = "Quais s√£o os principais fabricantes de inversores no cat√°logo?"
resp1 = client.chat(msg1, context)
context.append({"role": "user", "content": msg1})
context.append({"role": "assistant", "content": resp1})

# Segunda pergunta (com contexto)
msg2 = "E qual deles tem mais modelos?"
resp2 = client.chat(msg2, context)
print(resp2)
```

---

## üõ†Ô∏è INTEGRA√á√ÉO COM CAT√ÅLOGO

### Script de An√°lise em Lote

```python
from ollama_gpt import OllamaGPT
import json
from pathlib import Path

def analyze_catalog_quality(schemas_dir):
    """Analisa qualidade de todos os produtos"""
    
    client = OllamaGPT()
    results = []
    
    for json_file in Path(schemas_dir).glob("*_unified.json"):
        with open(json_file, 'r', encoding='utf-8') as f:
            products = json.load(f)
        
        for product in products[:10]:  # Primeiros 10 de cada categoria
            analysis = client.analyze_product(product)
            results.append({
                "product_id": product.get('id'),
                "product_name": product.get('name'),
                "category": product.get('category'),
                "quality_score": analysis.get('quality_score', 0),
                "confidence": analysis.get('category_confidence', 0)
            })
    
    # Ordenar por quality_score
    results.sort(key=lambda x: x['quality_score'])
    
    # Produtos com pior qualidade
    print("\nüî¥ Produtos que precisam de aten√ß√£o:")
    for item in results[:10]:
        print(f"  {item['product_name'][:50]}")
        print(f"    Qualidade: {item['quality_score']}/10")
    
    # Estat√≠sticas
    avg_quality = sum(r['quality_score'] for r in results) / len(results)
    print(f"\nüìä Qualidade m√©dia: {avg_quality:.1f}/10")
    
    return results

# Executar
results = analyze_catalog_quality("../data/catalog/unified_schemas")
```

---

## üéØ CASOS DE USO AVAN√áADOS

### 1. Gera√ß√£o de Tags Autom√°ticas

```python
def generate_tags(product):
    client = OllamaGPT()
    
    prompt = f"""Baseado neste produto, gere 5-10 tags relevantes:
    
    Nome: {product['name']}
    Categoria: {product['category']}
    Descri√ß√£o: {product.get('description', '')}
    
    Retorne apenas as tags separadas por v√≠rgula."""
    
    tags = client.generate(prompt, temperature=0.3, max_tokens=100)
    return [t.strip() for t in tags.split(',')]

# Uso
tags = generate_tags({
    "name": "Inversor Growatt MIN 3000TL-X",
    "category": "inverters",
    "description": "Inversor monof√°sico 3kW com 2 MPPT"
})
print(tags)
# Output: ['inversor', 'growatt', 'monof√°sico', '3kW', 'MPPT', 'grid-tie']
```

---

### 2. Compara√ß√£o de Produtos

```python
def compare_products(product1, product2):
    client = OllamaGPT()
    
    prompt = f"""Compare estes dois produtos:

    Produto 1:
    Nome: {product1['name']}
    Fabricante: {product1['manufacturer']}
    Specs: {json.dumps(product1.get('specifications', {}))}
    
    Produto 2:
    Nome: {product2['name']}
    Fabricante: {product2['manufacturer']}
    Specs: {json.dumps(product2.get('specifications', {}))}
    
    Retorne uma compara√ß√£o estruturada destacando:
    - Principais diferen√ßas
    - Vantagens de cada um
    - Recomenda√ß√£o de uso"""
    
    return client.generate(prompt, temperature=0.5, max_tokens=500)
```

---

### 3. Resposta a Perguntas sobre Produtos

```python
def answer_product_question(product, question):
    client = OllamaGPT()
    
    context = f"""Produto: {product['name']}
    Fabricante: {product['manufacturer']}
    Descri√ß√£o: {product.get('description', '')}
    Especifica√ß√µes: {json.dumps(product.get('specifications', {}), indent=2)}
    """
    
    prompt = f"""{context}
    
    Pergunta: {question}
    
    Responda de forma t√©cnica e precisa:"""
    
    return client.generate(prompt, temperature=0.3)

# Uso
answer = answer_product_question(
    product={"name": "Inversor Growatt MIN 3000TL-X", ...},
    question="Este inversor suporta baterias?"
)
```

---

## üìà PERFORMANCE

### Benchmarks (no seu PC)

- **Teste 1:** Gera√ß√£o de texto (200 tokens) = ~5 segundos
- **Teste 2:** An√°lise de produto = ~8 segundos
- **Teste 3:** Melhorar descri√ß√£o = ~10 segundos

### Otimiza√ß√µes

```python
# Usar temperature baixa para respostas mais consistentes
client.generate(prompt, temperature=0.2)

# Limitar tokens para respostas mais r√°pidas
client.generate(prompt, max_tokens=100)

# Processar em batch quando poss√≠vel
products = [p1, p2, p3]
analyses = [client.analyze_product(p) for p in products]
```

---

## üîß CONFIGURA√á√ÉO

### Ajustar Modelo

```python
# Usar outro modelo
client = OllamaGPT(model="llama2:13b")

# Mudar URL (se Ollama estiver remoto)
client = OllamaGPT(base_url="http://192.168.1.100:11434")
```

### Par√¢metros de Gera√ß√£o

```python
response = client.generate(
    prompt="Seu prompt aqui",
    temperature=0.7,    # 0 = determin√≠stico, 1 = criativo
    max_tokens=2000,    # M√°ximo de tokens na resposta
    stream=True         # Streaming em tempo real
)
```

---

## üö® TROUBLESHOOTING

### Problema: "Connection refused"

**Solu√ß√£o:** Iniciar Ollama

```bash
ollama serve
```

### Problema: Respostas lentas

**Solu√ß√µes:**

1. Reduzir `max_tokens`
2. Usar `temperature` mais baixa
3. Fechar outros programas pesados

### Problema: Modelo n√£o encontrado

**Solu√ß√£o:** Verificar modelos instalados

```bash
ollama list
```

---

## üìö RECURSOS ADICIONAIS

### Comandos Ollama CLI

```bash
# Listar modelos
ollama list

# Rodar modelo interativo
ollama run gpt-oss:20b

# Ver informa√ß√µes do modelo
ollama show gpt-oss:20b

# Remover modelo
ollama rm gpt-oss:20b

# Baixar modelo
ollama pull gpt-oss:20b
```

### API REST Direta

```bash
# Gerar texto
curl http://localhost:11434/api/generate -d '{
  "model": "gpt-oss:20b",
  "prompt": "Por que o c√©u √© azul?"
}'

# Chat
curl http://localhost:11434/api/chat -d '{
  "model": "gpt-oss:20b",
  "messages": [{"role": "user", "content": "Ol√°!"}]
}'
```

---

## ‚úÖ CHECKLIST DE USO

- [x] Ollama instalado (v0.12.3)
- [x] Modelo gpt-oss:20b baixado (13 GB)
- [x] Script Python criado (`ollama_gpt.py`)
- [x] Testes executados com sucesso
- [ ] Integrado ao pipeline de cat√°logo
- [ ] Dashboard de an√°lise criado
- [ ] API REST implementada

---

**üéâ Ollama GPT-OSS 20B pronto para uso!**

**Pr√≥ximos passos sugeridos:**

1. Analisar qualidade dos 1,123 produtos
2. Gerar descri√ß√µes melhoradas
3. Criar sistema de tags autom√°tico
4. Implementar chatbot de suporte
