# ğŸ“ ConfiguraÃ§Ã£o de Logging - YSH Data Pipeline

## ğŸ¯ Objetivo

Configurar o sistema de logging para que os arquivos de log **NÃƒO sejam commitados** no repositÃ³rio Git, mas sejam salvos apenas localmente ou enviados para sistemas de monitoramento.

---

## ğŸš« Problema Identificado

Os scripts estavam gerando arquivos JSON de log continuamente no diretÃ³rio `processed_data/`:

- `aneel_processed_*.json` (dados processados da ANEEL)
- `realtime_monitoring_*.json` (monitoramento em tempo real)

**Total**: 130+ arquivos gerados a cada execuÃ§Ã£o!

---

## âœ… SoluÃ§Ã£o Implementada

### 1. **`.gitignore` Criado**

Arquivo criado em: `c:\Users\fjuni\ysh_medusa\ysh-store\backend\data\.gitignore`

**Ignora**:

```gitignore
# Dados processados
processed_data/
**/processed_data/
*.json                    # Todos os JSONs
!package.json             # EXCETO package.json
!tsconfig.json            # EXCETO tsconfig.json
!**/schemas/**/*.json     # EXCETO schemas

# Logs
*.log
logs/
```

### 2. **Containers Docker Parados**

```powershell
docker compose down
```

Todos os 19 containers foram parados com sucesso.

### 3. **Arquivos de Log Limpos**

```powershell
Remove-Item processed_data\*.json -Force
```

---

## ğŸ”§ ConfiguraÃ§Ã£o Recomendada para Logging

### **OpÃ§Ã£o 1: Logging Apenas em Docker Volumes** âœ… RECOMENDADO

Modificar os scripts Python para salvar logs **dentro dos volumes Docker**:

```python
# Em vez de:
output_path = "processed_data/aneel_processed_{timestamp}.json"

# Use:
output_path = "/var/log/ysh-pipeline/aneel_processed_{timestamp}.json"
```

No `docker-compose.yml`:

```yaml
services:
  worker:
    volumes:
      - ./logs:/var/log/ysh-pipeline  # Mapeado para logs/ (jÃ¡ ignorado)
```

### **OpÃ§Ã£o 2: Enviar Logs para Grafana Loki** ğŸš€ PRODUÃ‡ÃƒO

Modificar scripts para usar **logging estruturado**:

```python
import logging
import json

logger = logging.getLogger(__name__)

# Configurar handler para Loki
handler = logging.handlers.HTTPHandler(
    'loki:3100', 
    '/loki/api/v1/push',
    method='POST'
)
logger.addHandler(handler)

# Log estruturado
logger.info(json.dumps({
    "timestamp": datetime.now().isoformat(),
    "source": "aneel_fetcher",
    "records_processed": 1000,
    "status": "success"
}))
```

### **OpÃ§Ã£o 3: Rotation Local com Limpeza AutomÃ¡tica** ğŸ”„

Usar `RotatingFileHandler` do Python:

```python
import logging
from logging.handlers import RotatingFileHandler

logger = logging.getLogger(__name__)

# MÃ¡ximo 10MB por arquivo, 5 arquivos no total
handler = RotatingFileHandler(
    'logs/pipeline.log',
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5
)

logger.addHandler(handler)
```

---

## ğŸ“Š Estrutura de DiretÃ³rios Recomendada

```
data-pipeline/
â”œâ”€â”€ logs/                    # âœ… IGNORADO pelo Git
â”‚   â”œâ”€â”€ pipeline.log
â”‚   â”œâ”€â”€ aneel_fetcher.log
â”‚   â””â”€â”€ realtime.log
â”œâ”€â”€ processed_data/          # âœ… IGNORADO pelo Git
â”‚   â”œâ”€â”€ aneel_*.json
â”‚   â””â”€â”€ realtime_*.json
â”œâ”€â”€ docker-data/             # âœ… IGNORADO pelo Git
â”‚   â”œâ”€â”€ postgres/
â”‚   â”œâ”€â”€ redis/
â”‚   â””â”€â”€ dynamodb/
â”œâ”€â”€ schemas/                 # âœ… COMMITADO (schemas sÃ£o cÃ³digo)
â”‚   â””â”€â”€ *.json
â””â”€â”€ *.py                     # âœ… COMMITADO (cÃ³digo fonte)
```

---

## ğŸ› ï¸ Scripts Modificados

### **1. `aneel_data_fetcher.py`**

Modificar para usar logging estruturado:

```python
import logging
import os
from datetime import datetime

# Configurar logger
LOG_DIR = os.getenv('LOG_DIR', 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'{LOG_DIR}/aneel_fetcher.log'),
        logging.StreamHandler()  # TambÃ©m mostra no console
    ]
)
logger = logging.getLogger(__name__)

# Em vez de salvar JSON:
# with open(f'processed_data/aneel_{timestamp}.json', 'w') as f:
#     json.dump(data, f)

# Use:
logger.info(f"Processed {len(data)} ANEEL records", extra={
    'count': len(data),
    'timestamp': datetime.now().isoformat()
})
```

### **2. `realtime_processor.py`**

```python
import logging
import os

LOG_DIR = os.getenv('LOG_DIR', 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    handlers=[
        logging.FileHandler(f'{LOG_DIR}/realtime.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Em vez de salvar JSON a cada execuÃ§Ã£o:
logger.info("Realtime monitoring cycle completed", extra={
    'metrics': metrics_dict
})
```

---

## ğŸš€ Como Executar com Logging Correto

### **Desenvolvimento Local**

```powershell
# Definir diretÃ³rio de logs
$env:LOG_DIR = "logs"

# Executar script
python aneel_data_fetcher.py
```

### **Docker**

```yaml
services:
  worker:
    environment:
      - LOG_DIR=/var/log/ysh-pipeline
    volumes:
      - ./logs:/var/log/ysh-pipeline
```

```powershell
docker compose up -d
```

---

## ğŸ“ˆ Monitoramento com Grafana

### **1. Configurar Promtail (Log Shipper)**

```yaml
# docker-compose.yml
services:
  promtail:
    image: grafana/promtail:latest
    volumes:
      - ./logs:/var/log/ysh-pipeline:ro
      - ./promtail-config.yml:/etc/promtail/config.yml
    command: -config.file=/etc/promtail/config.yml
```

### **2. Visualizar no Grafana**

Dashboard: <http://localhost:3001>

1. Acessar **Explore**
2. Selecionar datasource **Loki**
3. Query: `{job="ysh-pipeline"}`

---

## ğŸ§¹ Limpeza PeriÃ³dica (Opcional)

### **Script PowerShell**

Criar `cleanup-logs.ps1`:

```powershell
# Remover logs com mais de 7 dias
$logDir = "logs"
$daysToKeep = 7

Get-ChildItem $logDir -Recurse -File | 
    Where-Object { $_.LastWriteTime -lt (Get-Date).AddDays(-$daysToKeep) } | 
    Remove-Item -Force

Write-Host "âœ… Logs com mais de $daysToKeep dias foram removidos"
```

### **Cron Job (Linux/WSL)**

```bash
# Adicionar ao crontab
0 2 * * * find /path/to/logs -type f -mtime +7 -delete
```

---

## âœ… Checklist de ValidaÃ§Ã£o

- [x] `.gitignore` criado e configurado
- [x] Containers Docker parados
- [x] Arquivos de log existentes removidos
- [ ] Scripts Python modificados para usar logging estruturado
- [ ] Docker volumes configurados para logs
- [ ] Promtail/Loki configurado (opcional)
- [ ] Dashboard Grafana para logs (opcional)

---

## ğŸ¯ PrÃ³ximos Passos

1. **Modificar scripts Python** para usar logging estruturado
2. **Testar localmente** sem gerar arquivos JSON
3. **Configurar Promtail/Loki** para produÃ§Ã£o
4. **Criar dashboards Grafana** para visualizaÃ§Ã£o de logs
5. **Configurar alertas** para erros crÃ­ticos

---

## ğŸ“ Comandos Ãšteis

```powershell
# Ver logs em tempo real (Docker)
docker compose logs -f worker

# Ver logs salvos localmente
Get-Content logs\pipeline.log -Tail 50 -Wait

# Limpar todos os logs
Remove-Item logs\*.log -Force

# Verificar arquivos ignorados pelo Git
git status --ignored

# Remover arquivos jÃ¡ commitados que agora estÃ£o no .gitignore
git rm -r --cached processed_data/
git commit -m "Remove processed_data from tracking"
```

---

## ğŸ‰ Resultado Final

âœ… **Logs nÃ£o sÃ£o mais commitados no Git**  
âœ… **Arquivos salvos localmente em `logs/`**  
âœ… **Docker volumes isolados**  
âœ… **Monitoramento via Grafana (opcional)**  
âœ… **Limpeza automÃ¡tica com rotation**

---

**Documentado em**: 2025-10-14  
**VersÃ£o**: 1.0  
**Status**: âœ… IMPLEMENTADO
