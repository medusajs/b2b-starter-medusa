# ü§ñ IA Local para Evolu√ß√£o de Imagens - An√°lise de Viabilidade

## üì¶ Extens√£o: Python Image Preview (076923.python-image-preview)

### Funcionalidades Nativas

#### 1. **Preview de M√∫ltiplos Formatos**

- ‚úÖ NumPy arrays (`.npy`, `.npz`)
- ‚úÖ Pillow/PIL images
- ‚úÖ OpenCV images (BGR/RGB)
- ‚úÖ Matplotlib figures
- ‚úÖ Plotly plots
- ‚úÖ ImageIO
- ‚úÖ Scikit-Image
- ‚úÖ TensorFlow tensors
- ‚úÖ PyTorch tensors

#### 2. **Visualiza√ß√£o Interativa**

```python
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# Preview direto no VSCode
img = Image.open('produto.jpg')
# Hover ou comando para visualizar

arr = np.array(img)
# Preview de arrays NumPy automaticamente
```

#### 3. **Integra√ß√£o com Notebooks**

- Preview inline em Jupyter notebooks
- Suporte a m√∫ltiplos backends de visualiza√ß√£o
- Debugging visual de tensores

---

## üß† Modelos de IA Local - An√°lise T√©cnica

### ü¶ô **Ollama - Modelos Multimodais**

#### Modelos Dispon√≠veis (Outubro 2025)

##### 1. **LLaVA 1.6 (34B)** ‚≠ê RECOMENDADO

```bash
ollama pull llava:34b
```

**Capacidades:**

- ‚úÖ An√°lise detalhada de imagens de produtos
- ‚úÖ Descri√ß√£o autom√°tica de caracter√≠sticas
- ‚úÖ Detec√ß√£o de logos e textos em pain√©is
- ‚úÖ Identifica√ß√£o de tipo de produto (inversor, painel, kit)
- ‚úÖ Extra√ß√£o de especifica√ß√µes vis√≠veis (pot√™ncia, modelo)
- ‚úÖ Avalia√ß√£o de qualidade da imagem

**Exemplo de Uso:**

```python
import ollama

response = ollama.chat(
    model='llava:34b',
    messages=[{
        'role': 'user',
        'content': 'Analise esta imagem de produto solar. Identifique: tipo de produto, fabricante vis√≠vel, pot√™ncia, qualidade da imagem (1-10).',
        'images': ['produto.jpg']
    }]
)

print(response['message']['content'])
# Output: "Este √© um inversor grid-tie da marca SAJ, modelo R5-3K-T2. 
#          A pot√™ncia nominal √© 3kW (vis√≠vel no r√≥tulo frontal). 
#          Qualidade da imagem: 8/10 - boa resolu√ß√£o, logo n√≠tido, 
#          fundo limpo. Sugest√µes: aumentar contraste do texto inferior."
```

**Requisitos:**

- RAM: 32GB m√≠nimo (modelo 34B)
- VRAM: 24GB GPU (recomendado RTX 4090)
- CPU: AMD Ryzen 9 / Intel i9 (sem GPU)

##### 2. **LLaVA 1.6 (13B)** üí° BALANCEADO

```bash
ollama pull llava:13b
```

**Capacidades:**

- ‚úÖ An√°lise r√°pida de produtos
- ‚úÖ Descri√ß√£o b√°sica de caracter√≠sticas
- ‚úÖ Detec√ß√£o de tipo de produto
- ‚ö†Ô∏è Menos preciso em especifica√ß√µes t√©cnicas
- ‚úÖ Boa rela√ß√£o performance/qualidade

**Requisitos:**

- RAM: 16GB m√≠nimo
- VRAM: 8GB GPU (RTX 3070+)

##### 3. **BakLLaVA (7B)** üöÄ R√ÅPIDO

```bash
ollama pull bakllava
```

**Capacidades:**

- ‚úÖ Preview r√°pido de imagens
- ‚úÖ Classifica√ß√£o b√°sica
- ‚ö†Ô∏è Limitado em detalhes t√©cnicos
- ‚úÖ Ideal para triagem inicial

**Requisitos:**

- RAM: 8GB m√≠nimo
- VRAM: 4GB GPU (RTX 3060)

---

### üîì **Modelos Open Source 20B+**

#### 1. **CogVLM (17B Visual + 17B Language)** ‚≠ê MELHOR OSS

```bash
# Instala√ß√£o via HuggingFace
pip install transformers accelerate
```

**Capacidades:**

- ‚úÖ Estado da arte em compreens√£o visual
- ‚úÖ OCR nativo (leitura de textos em produtos)
- ‚úÖ Reasoning visual complexo
- ‚úÖ Detec√ß√£o precisa de componentes
- ‚úÖ An√°lise de diagramas t√©cnicos

**Exemplo:**

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from PIL import Image

model = AutoModelForCausalLM.from_pretrained(
    "THUDM/cogvlm-chat-hf",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

query = "Identifique o fabricante, modelo e pot√™ncia deste inversor"
image = Image.open("inversor.jpg")

response = model.chat(tokenizer, image, query)
# "Fabricante: SAJ, Modelo: R5-3K-T2, Pot√™ncia: 3000W"
```

**Requisitos:**

- VRAM: 40GB (A100) ou 2x RTX 4090
- RAM: 64GB

#### 2. **BLIP-2 (OPT-6.7B)** üíº ESPECIALIZADO

```python
from transformers import Blip2Processor, Blip2ForConditionalGeneration

processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-6.7b")
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-6.7b")

# Gera√ß√£o de captions
inputs = processor(images=image, return_tensors="pt")
outputs = model.generate(**inputs)
caption = processor.decode(outputs[0], skip_special_tokens=True)
```

**Capacidades:**

- ‚úÖ Excelente para descri√ß√µes de produtos
- ‚úÖ Image captioning autom√°tico
- ‚úÖ Visual question answering
- ‚ö†Ô∏è Menos preciso em OCR

**Requisitos:**

- VRAM: 16GB (RTX 4080)
- RAM: 32GB

#### 3. **Qwen-VL (9.6B)** üá®üá≥ MULTILINGUAL

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen-VL-Chat",
    trust_remote_code=True
)
```

**Capacidades:**

- ‚úÖ Suporte a portugu√™s nativo
- ‚úÖ Bom OCR para textos PT-BR
- ‚úÖ Compreens√£o de contexto brasileiro
- ‚úÖ An√°lise de produtos locais

---

## üéØ Casos de Uso para YSH Store

### 1. **An√°lise Autom√°tica de Qualidade** üîç

```python
def analyze_image_quality_ai(image_path):
    """Usa LLaVA para avaliar qualidade da imagem"""
    
    prompt = """Analise esta imagem de produto fotovoltaico:
    
    1. Qualidade da foto (1-10): resolu√ß√£o, nitidez, ilumina√ß√£o
    2. Problemas detectados: desfoque, baixo contraste, reflexos
    3. Logo do fabricante: vis√≠vel (sim/n√£o), n√≠tido (sim/n√£o)
    4. Informa√ß√µes leg√≠veis: r√≥tulos, especifica√ß√µes, textos
    5. Sugest√µes de melhoria
    
    Responda em formato JSON."""
    
    response = ollama.chat(
        model='llava:34b',
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image_path]
        }]
    )
    
    return json.loads(response['message']['content'])
```

**Output Esperado:**

```json
{
  "quality_score": 8,
  "problems": ["leve reflexo no canto superior", "texto inferior levemente desfocado"],
  "logo_visible": true,
  "logo_sharp": true,
  "text_readable": ["SAJ", "R5-3K-T2", "3000W"],
  "suggestions": [
    "Aumentar contraste em 10%",
    "Aplicar leve sharpen no texto inferior",
    "Crop para remover bordas desnecess√°rias"
  ]
}
```

### 2. **Extra√ß√£o Inteligente de Metadados** üìù

```python
def extract_product_metadata_ai(image_path):
    """Extrai informa√ß√µes do produto usando IA"""
    
    prompt = """Extraia as seguintes informa√ß√µes desta imagem:
    
    - Fabricante (marca)
    - Categoria (inversor/painel/bateria/kit)
    - Tipo (grid-tie/h√≠brido/off-grid/micro para inversores; mono/bifacial para pain√©is)
    - Modelo (c√≥digo exato)
    - Pot√™ncia (em W ou kW)
    - Tecnologia vis√≠vel (ex: MPPT, N-Type, etc)
    
    Retorne JSON estruturado."""
    
    response = ollama.chat(
        model='llava:34b',
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image_path]
        }]
    )
    
    return json.loads(response['message']['content'])
```

**Output Esperado:**

```json
{
  "manufacturer": "SAJ",
  "category": "inverter",
  "type": "grid-tie",
  "model": "R5-3K-T2",
  "power": "3000W",
  "power_kw": 3.0,
  "technology": ["2 MPPT", "Monof√°sico", "220V"],
  "confidence": 0.95
}
```

### 3. **Detec√ß√£o de Tipo de Imagem** üé®

```python
def detect_image_type_ai(image_path):
    """Classifica tipo de imagem (logo simples, diagrama, foto real, render)"""
    
    prompt = """Classifique esta imagem em uma das categorias:
    
    1. logo_simples: Logo/produto em fundo branco, sem detalhes complexos
    2. diagrama_tecnico: Diagrama, esquema, desenho t√©cnico
    3. produto_fotografia: Foto real do produto, ilumina√ß√£o natural
    4. produto_render: Renderiza√ß√£o 3D, CGI, imagem sint√©tica
    
    Retorne apenas a categoria."""
    
    response = ollama.chat(
        model='llava:13b',  # Modelo menor suficiente para classifica√ß√£o
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image_path]
        }]
    )
    
    return response['message']['content'].strip()
```

**Integra√ß√£o com Perfis de Otimiza√ß√£o:**

```python
IMAGE_OPTIMIZATION_PROFILES = {
    'logo_simples': {'quality': 98, 'denoise': 0, 'sharpen': 0},
    'diagrama_tecnico': {'quality': 95, 'denoise': 1, 'sharpen': 0},
    'produto_fotografia': {'quality': 90, 'denoise': 2, 'sharpen': 0.5},
    'produto_render': {'quality': 88, 'denoise': 3, 'sharpen': 1.0}
}

image_type = detect_image_type_ai(image_path)
profile = IMAGE_OPTIMIZATION_PROFILES[image_type]
```

### 4. **Gera√ß√£o Autom√°tica de Nomenclatura** üè∑Ô∏è

```python
def generate_filename_ai(image_path):
    """Gera nome padronizado usando IA"""
    
    metadata = extract_product_metadata_ai(image_path)
    
    # Formato: FABRICANTE-CATEGORIA-TIPO-MODELO-POTENCIA
    parts = [
        metadata.get('manufacturer', 'UNKNOWN'),
        metadata['category'][:3].upper(),  # INV, PAN, etc
        metadata.get('type', ''),
        metadata.get('model', ''),
        f"{metadata.get('power_kw', '')}KW" if metadata.get('power_kw') else ''
    ]
    
    filename = '-'.join([p for p in parts if p])
    
    return filename + '.webp'
```

### 5. **Sugest√µes de Melhoria Autom√°tica** üéØ

```python
def suggest_improvements_ai(image_path):
    """IA sugere melhorias espec√≠ficas"""
    
    prompt = """Como especialista em fotografia de produtos, analise esta imagem e sugira:
    
    1. Ajustes de cor (satura√ß√£o, temperatura, contraste)
    2. Recorte ideal (aspect ratio, margens)
    3. Corre√ß√µes de perspectiva
    4. Remo√ß√£o de elementos indesejados
    5. Melhorias de nitidez espec√≠ficas
    
    Seja espec√≠fico com valores num√©ricos quando poss√≠vel."""
    
    response = ollama.chat(
        model='llava:34b',
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image_path]
        }]
    )
    
    return response['message']['content']
```

---

## üöÄ Pipeline Proposto: IA + Processamento Tradicional

### Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Imagem Original ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. An√°lise IA (LLaVA)  ‚îÇ ‚Üê Extra√ß√£o de metadados
‚îÇ  - Fabricante           ‚îÇ   Tipo de imagem
‚îÇ  - Modelo               ‚îÇ   Avalia√ß√£o de qualidade
‚îÇ  - Pot√™ncia             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. Classifica√ß√£o       ‚îÇ ‚Üê Determina perfil
‚îÇ  - logo_simples         ‚îÇ   de otimiza√ß√£o
‚îÇ  - diagrama_tecnico     ‚îÇ
‚îÇ  - produto_fotografia   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. Processamento       ‚îÇ ‚Üê OpenCV + Pillow
‚îÇ  - Perfil espec√≠fico    ‚îÇ   com par√¢metros
‚îÇ  - Quality 88-98        ‚îÇ   ajustados por IA
‚îÇ  - Denoise 0-3          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. Nomenclatura        ‚îÇ ‚Üê Nome padronizado
‚îÇ  FABRICANTE-CAT-MODELO  ‚îÇ   gerado por IA
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. Vers√µes Responsivas ‚îÇ ‚Üê 4 tamanhos
‚îÇ  original/large/med/th  ‚îÇ   (1200/800/400)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Script Integrado

```python
#!/usr/bin/env python3
"""
Pipeline Inteligente de Processamento de Imagens
Combina IA local (Ollama) + processamento tradicional
"""

import ollama
from PIL import Image
import cv2
import json


class AIImageProcessor:
    def __init__(self, model='llava:13b'):
        self.model = model
    
    def process_image(self, image_path, distributor='ODEX'):
        """Pipeline completo de processamento"""
        
        print(f'ü§ñ Analisando com IA: {image_path}')
        
        # 1. Extra√ß√£o de metadados por IA
        metadata = self.extract_metadata_ai(image_path)
        print(f'   Fabricante: {metadata.get("manufacturer")}')
        print(f'   Modelo: {metadata.get("model")}')
        print(f'   Pot√™ncia: {metadata.get("power")}')
        
        # 2. Classifica√ß√£o de tipo
        image_type = self.classify_image_type(image_path)
        print(f'   Tipo detectado: {image_type}')
        
        # 3. An√°lise de qualidade
        quality = self.analyze_quality(image_path)
        print(f'   Qualidade: {quality["score"]}/10')
        
        # 4. Gerar nome padronizado
        filename = self.generate_standard_name(metadata, distributor)
        print(f'   Nome padronizado: {filename}')
        
        # 5. Selecionar perfil de otimiza√ß√£o
        profile = self.select_optimization_profile(image_type, quality)
        print(f'   Perfil: quality={profile["quality"]}, denoise={profile["denoise"]}')
        
        # 6. Processar imagem
        output_path = self.optimize_image(image_path, filename, profile)
        
        return {
            'metadata': metadata,
            'type': image_type,
            'quality': quality,
            'filename': filename,
            'profile': profile,
            'output': output_path
        }
    
    def extract_metadata_ai(self, image_path):
        """Extrai metadados usando LLaVA"""
        
        prompt = """Extraia informa√ß√µes desta imagem de produto solar.
        Retorne JSON: {"manufacturer": "...", "category": "...", "model": "...", "power": "..."}"""
        
        try:
            response = ollama.chat(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': prompt,
                    'images': [image_path]
                }]
            )
            
            return json.loads(response['message']['content'])
        except:
            return {}
    
    def classify_image_type(self, image_path):
        """Classifica tipo de imagem"""
        
        prompt = """Classifique esta imagem em UMA categoria:
        - logo_simples
        - diagrama_tecnico
        - produto_fotografia
        - produto_render
        Responda apenas a categoria."""
        
        try:
            response = ollama.chat(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': prompt,
                    'images': [image_path]
                }]
            )
            
            return response['message']['content'].strip()
        except:
            return 'produto_fotografia'  # fallback
    
    def analyze_quality(self, image_path):
        """Analisa qualidade da imagem"""
        
        prompt = """Avalie a qualidade desta imagem (1-10).
        Retorne JSON: {"score": 8, "problems": ["..."]}"""
        
        try:
            response = ollama.chat(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': prompt,
                    'images': [image_path]
                }]
            )
            
            return json.loads(response['message']['content'])
        except:
            return {'score': 7, 'problems': []}
    
    def generate_standard_name(self, metadata, distributor):
        """Gera nome padronizado"""
        
        parts = [
            metadata.get('manufacturer', 'UNKNOWN').upper(),
            metadata.get('category', 'PROD')[:3].upper(),
            metadata.get('model', '').upper(),
            metadata.get('power', '').upper(),
            distributor.upper()
        ]
        
        return '-'.join([p for p in parts if p])
    
    def select_optimization_profile(self, image_type, quality):
        """Seleciona perfil baseado em tipo e qualidade"""
        
        profiles = {
            'logo_simples': {'quality': 98, 'denoise': 0, 'sharpen': 0},
            'diagrama_tecnico': {'quality': 95, 'denoise': 1, 'sharpen': 0},
            'produto_fotografia': {'quality': 90, 'denoise': 2, 'sharpen': 0.5},
            'produto_render': {'quality': 88, 'denoise': 3, 'sharpen': 1.0}
        }
        
        profile = profiles.get(image_type, profiles['produto_fotografia'])
        
        # Ajustar baseado em qualidade
        if quality.get('score', 7) < 6:
            profile['denoise'] += 1
            profile['sharpen'] += 0.5
        
        return profile
    
    def optimize_image(self, input_path, filename, profile):
        """Otimiza imagem com perfil selecionado"""
        
        img = Image.open(input_path)
        
        # Processar com OpenCV se necess√°rio
        if profile['denoise'] > 0 or profile['sharpen'] > 0:
            img_array = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            
            if profile['denoise'] > 0:
                img_array = cv2.fastNlMeansDenoisingColored(img_array, None, profile['denoise'] * 3, 10, 7, 21)
            
            if profile['sharpen'] > 0:
                kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) * profile['sharpen']
                img_array = cv2.filter2D(img_array, -1, kernel)
            
            img = Image.fromarray(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))
        
        # Salvar
        output_path = f'static/images-ai-processed/{filename}.webp'
        img.save(output_path, 'WEBP', quality=profile['quality'], method=6)
        
        return output_path


# Uso
processor = AIImageProcessor(model='llava:13b')
result = processor.process_image('static/images-cat√°logo_distribuidores/ODEX-INVERTERS/276954.jpg', 'ODEX')
```

---

## üìä Compara√ß√£o de Modelos

| Modelo | Tamanho | VRAM | Velocidade | Qualidade | Recomendado Para |
|--------|---------|------|------------|-----------|------------------|
| **LLaVA 34B** | 34GB | 24GB | Lento (10s/img) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Produ√ß√£o, an√°lise detalhada |
| **LLaVA 13B** | 13GB | 8GB | M√©dio (3s/img) | ‚≠ê‚≠ê‚≠ê‚≠ê | **Recomendado** balanceado |
| **BakLLaVA 7B** | 7GB | 4GB | R√°pido (1s/img) | ‚≠ê‚≠ê‚≠ê | Preview, triagem r√°pida |
| **CogVLM 34B** | 34GB | 40GB | Lento (15s/img) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Melhor OCR, texto t√©cnico |
| **BLIP-2 6.7B** | 6.7GB | 16GB | R√°pido (2s/img) | ‚≠ê‚≠ê‚≠ê‚≠ê | Captions, descri√ß√µes |
| **Qwen-VL 9.6B** | 9.6GB | 16GB | M√©dio (4s/img) | ‚≠ê‚≠ê‚≠ê‚≠ê | Suporte PT-BR |

---

## üí° Recomenda√ß√£o Final

### Setup Ideal para YSH Store

1. **Modelo Principal**: **LLaVA 13B** (Ollama)
   - Melhor custo-benef√≠cio
   - Roda em GPU mainstream (RTX 3070+)
   - Qualidade suficiente para metadados

2. **Backup**: **BLIP-2** (HuggingFace)
   - Para gera√ß√£o de descri√ß√µes
   - Fallback quando Ollama indispon√≠vel

3. **Pipeline**:

   ```
   Imagem ‚Üí LLaVA (metadados) ‚Üí Perfil ‚Üí OpenCV (processamento) ‚Üí WebP (4 tamanhos)
   ```

### Pr√≥ximos Passos

1. ‚úÖ Instalar Ollama + LLaVA 13B
2. ‚úÖ Criar script de teste com 10 imagens
3. ‚úÖ Validar qualidade de extra√ß√£o vs manual
4. ‚úÖ Integrar com pipeline existente
5. ‚úÖ Processar lote completo (278 imagens)

**√öltima atualiza√ß√£o**: 13 de outubro de 2025  
**Status**: üéØ Pronto para Implementa√ß√£o
