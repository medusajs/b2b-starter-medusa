# ğŸ¤– IA Local para EvoluÃ§Ã£o de Imagens - AnÃ¡lise de Viabilidade

## ğŸ“¦ ExtensÃ£o: Python Image Preview (076923.python-image-preview)

### Funcionalidades Nativas

#### 1. **Preview de MÃºltiplos Formatos**

- âœ… NumPy arrays (`.npy`, `.npz`)
- âœ… Pillow/PIL images
- âœ… OpenCV images (BGR/RGB)
- âœ… Matplotlib figures
- âœ… Plotly plots
- âœ… ImageIO
- âœ… Scikit-Image
- âœ… TensorFlow tensors
- âœ… PyTorch tensors

#### 2. **VisualizaÃ§Ã£o Interativa**

```python
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# Preview direto no VSCode
img = Image.open('produto.jpg')
# Hover ou comando para visualizar

arr = np.array(img)
# Preview de arrays NumPy automaticamente
```

#### 3. **IntegraÃ§Ã£o com Notebooks**

- Preview inline em Jupyter notebooks
- Suporte a mÃºltiplos backends de visualizaÃ§Ã£o
- Debugging visual de tensores

---

## ğŸ§  Modelos de IA Local - AnÃ¡lise TÃ©cnica

### ğŸ¦™ **Ollama - Modelos Multimodais**

#### Modelos DisponÃ­veis (Outubro 2025)

##### 1. **LLaVA 1.6 (34B)** â­ RECOMENDADO

```bash
ollama pull llava:34b
```

**Capacidades:**

- âœ… AnÃ¡lise detalhada de imagens de produtos
- âœ… DescriÃ§Ã£o automÃ¡tica de caracterÃ­sticas
- âœ… DetecÃ§Ã£o de logos e textos em painÃ©is
- âœ… IdentificaÃ§Ã£o de tipo de produto (inversor, painel, kit)
- âœ… ExtraÃ§Ã£o de especificaÃ§Ãµes visÃ­veis (potÃªncia, modelo)
- âœ… AvaliaÃ§Ã£o de qualidade da imagem

**Exemplo de Uso:**

```python
import ollama

response = ollama.chat(
    model='llava:34b',
    messages=[{
        'role': 'user',
        'content': 'Analise esta imagem de produto solar. Identifique: tipo de produto, fabricante visÃ­vel, potÃªncia, qualidade da imagem (1-10).',
        'images': ['produto.jpg']
    }]
)

print(response['message']['content'])
# Output: "Este Ã© um inversor grid-tie da marca SAJ, modelo R5-3K-T2. 
#          A potÃªncia nominal Ã© 3kW (visÃ­vel no rÃ³tulo frontal). 
#          Qualidade da imagem: 8/10 - boa resoluÃ§Ã£o, logo nÃ­tido, 
#          fundo limpo. SugestÃµes: aumentar contraste do texto inferior."
```

**Requisitos:**

- RAM: 32GB mÃ­nimo (modelo 34B)
- VRAM: 24GB GPU (recomendado RTX 4090)
- CPU: AMD Ryzen 9 / Intel i9 (sem GPU)

##### 2. **LLaVA 1.6 (13B)** ğŸ’¡ BALANCEADO

```bash
ollama pull llava:13b
```

**Capacidades:**

- âœ… AnÃ¡lise rÃ¡pida de produtos
- âœ… DescriÃ§Ã£o bÃ¡sica de caracterÃ­sticas
- âœ… DetecÃ§Ã£o de tipo de produto
- âš ï¸ Menos preciso em especificaÃ§Ãµes tÃ©cnicas
- âœ… Boa relaÃ§Ã£o performance/qualidade

**Requisitos:**

- RAM: 16GB mÃ­nimo
- VRAM: 8GB GPU (RTX 3070+)

##### 3. **BakLLaVA (7B)** ğŸš€ RÃPIDO

```bash
ollama pull bakllava
```

**Capacidades:**

- âœ… Preview rÃ¡pido de imagens
- âœ… ClassificaÃ§Ã£o bÃ¡sica
- âš ï¸ Limitado em detalhes tÃ©cnicos
- âœ… Ideal para triagem inicial

**Requisitos:**

- RAM: 8GB mÃ­nimo
- VRAM: 4GB GPU (RTX 3060)

---

### ğŸ”“ **Modelos Open Source 20B+**

#### 1. **CogVLM (17B Visual + 17B Language)** â­ MELHOR OSS

```bash
# InstalaÃ§Ã£o via HuggingFace
pip install transformers accelerate
```

**Capacidades:**

- âœ… Estado da arte em compreensÃ£o visual
- âœ… OCR nativo (leitura de textos em produtos)
- âœ… Reasoning visual complexo
- âœ… DetecÃ§Ã£o precisa de componentes
- âœ… AnÃ¡lise de diagramas tÃ©cnicos

**Exemplo:**

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from PIL import Image

model = AutoModelForCausalLM.from_pretrained(
    "THUDM/cogvlm-chat-hf",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)

query = "Identifique o fabricante, modelo e potÃªncia deste inversor"
image = Image.open("inversor.jpg")

response = model.chat(tokenizer, image, query)
# "Fabricante: SAJ, Modelo: R5-3K-T2, PotÃªncia: 3000W"
```

**Requisitos:**

- VRAM: 40GB (A100) ou 2x RTX 4090
- RAM: 64GB

#### 2. **BLIP-2 (OPT-6.7B)** ğŸ’¼ ESPECIALIZADO

```python
from transformers import Blip2Processor, Blip2ForConditionalGeneration

processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-6.7b")
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-6.7b")

# GeraÃ§Ã£o de captions
inputs = processor(images=image, return_tensors="pt")
outputs = model.generate(**inputs)
caption = processor.decode(outputs[0], skip_special_tokens=True)
```

**Capacidades:**

- âœ… Excelente para descriÃ§Ãµes de produtos
- âœ… Image captioning automÃ¡tico
- âœ… Visual question answering
- âš ï¸ Menos preciso em OCR

**Requisitos:**

- VRAM: 16GB (RTX 4080)
- RAM: 32GB

#### 3. **Qwen-VL (9.6B)** ğŸ‡¨ğŸ‡³ MULTILINGUAL

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen-VL-Chat",
    trust_remote_code=True
)
```

**Capacidades:**

- âœ… Suporte a portuguÃªs nativo
- âœ… Bom OCR para textos PT-BR
- âœ… CompreensÃ£o de contexto brasileiro
- âœ… AnÃ¡lise de produtos locais

---

## ğŸ¯ Casos de Uso para YSH Store

### 1. **AnÃ¡lise AutomÃ¡tica de Qualidade** ğŸ”

```python
def analyze_image_quality_ai(image_path):
    """Usa LLaVA para avaliar qualidade da imagem"""
    
    prompt = """Analise esta imagem de produto fotovoltaico:
    
    1. Qualidade da foto (1-10): resoluÃ§Ã£o, nitidez, iluminaÃ§Ã£o
    2. Problemas detectados: desfoque, baixo contraste, reflexos
    3. Logo do fabricante: visÃ­vel (sim/nÃ£o), nÃ­tido (sim/nÃ£o)
    4. InformaÃ§Ãµes legÃ­veis: rÃ³tulos, especificaÃ§Ãµes, textos
    5. SugestÃµes de melhoria
    
    Responda em formato JSON."""
    
    response = ollama.chat(
        model='llava:34b',
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image_path]
        }]
    )
    
    return json.loads(response['message']['content'])
```

**Output Esperado:**

```json
{
  "quality_score": 8,
  "problems": ["leve reflexo no canto superior", "texto inferior levemente desfocado"],
  "logo_visible": true,
  "logo_sharp": true,
  "text_readable": ["SAJ", "R5-3K-T2", "3000W"],
  "suggestions": [
    "Aumentar contraste em 10%",
    "Aplicar leve sharpen no texto inferior",
    "Crop para remover bordas desnecessÃ¡rias"
  ]
}
```

### 2. **ExtraÃ§Ã£o Inteligente de Metadados** ğŸ“

```python
def extract_product_metadata_ai(image_path):
    """Extrai informaÃ§Ãµes do produto usando IA"""
    
    prompt = """Extraia as seguintes informaÃ§Ãµes desta imagem:
    
    - Fabricante (marca)
    - Categoria (inversor/painel/bateria/kit)
    - Tipo (grid-tie/hÃ­brido/off-grid/micro para inversores; mono/bifacial para painÃ©is)
    - Modelo (cÃ³digo exato)
    - PotÃªncia (em W ou kW)
    - Tecnologia visÃ­vel (ex: MPPT, N-Type, etc)
    
    Retorne JSON estruturado."""
    
    response = ollama.chat(
        model='llava:34b',
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image_path]
        }]
    )
    
    return json.loads(response['message']['content'])
```

**Output Esperado:**

```json
{
  "manufacturer": "SAJ",
  "category": "inverter",
  "type": "grid-tie",
  "model": "R5-3K-T2",
  "power": "3000W",
  "power_kw": 3.0,
  "technology": ["2 MPPT", "MonofÃ¡sico", "220V"],
  "confidence": 0.95
}
```

### 3. **DetecÃ§Ã£o de Tipo de Imagem** ğŸ¨

```python
def detect_image_type_ai(image_path):
    """Classifica tipo de imagem (logo simples, diagrama, foto real, render)"""
    
    prompt = """Classifique esta imagem em uma das categorias:
    
    1. logo_simples: Logo/produto em fundo branco, sem detalhes complexos
    2. diagrama_tecnico: Diagrama, esquema, desenho tÃ©cnico
    3. produto_fotografia: Foto real do produto, iluminaÃ§Ã£o natural
    4. produto_render: RenderizaÃ§Ã£o 3D, CGI, imagem sintÃ©tica
    
    Retorne apenas a categoria."""
    
    response = ollama.chat(
        model='llava:13b',  # Modelo menor suficiente para classificaÃ§Ã£o
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image_path]
        }]
    )
    
    return response['message']['content'].strip()
```

**IntegraÃ§Ã£o com Perfis de OtimizaÃ§Ã£o:**

```python
IMAGE_OPTIMIZATION_PROFILES = {
    'logo_simples': {'quality': 98, 'denoise': 0, 'sharpen': 0},
    'diagrama_tecnico': {'quality': 95, 'denoise': 1, 'sharpen': 0},
    'produto_fotografia': {'quality': 90, 'denoise': 2, 'sharpen': 0.5},
    'produto_render': {'quality': 88, 'denoise': 3, 'sharpen': 1.0}
}

image_type = detect_image_type_ai(image_path)
profile = IMAGE_OPTIMIZATION_PROFILES[image_type]
```

### 4. **GeraÃ§Ã£o AutomÃ¡tica de Nomenclatura** ğŸ·ï¸

```python
def generate_filename_ai(image_path):
    """Gera nome padronizado usando IA"""
    
    metadata = extract_product_metadata_ai(image_path)
    
    # Formato: FABRICANTE-CATEGORIA-TIPO-MODELO-POTENCIA
    parts = [
        metadata.get('manufacturer', 'UNKNOWN'),
        metadata['category'][:3].upper(),  # INV, PAN, etc
        metadata.get('type', ''),
        metadata.get('model', ''),
        f"{metadata.get('power_kw', '')}KW" if metadata.get('power_kw') else ''
    ]
    
    filename = '-'.join([p for p in parts if p])
    
    return filename + '.webp'
```

### 5. **SugestÃµes de Melhoria AutomÃ¡tica** ğŸ¯

```python
def suggest_improvements_ai(image_path):
    """IA sugere melhorias especÃ­ficas"""
    
    prompt = """Como especialista em fotografia de produtos, analise esta imagem e sugira:
    
    1. Ajustes de cor (saturaÃ§Ã£o, temperatura, contraste)
    2. Recorte ideal (aspect ratio, margens)
    3. CorreÃ§Ãµes de perspectiva
    4. RemoÃ§Ã£o de elementos indesejados
    5. Melhorias de nitidez especÃ­ficas
    
    Seja especÃ­fico com valores numÃ©ricos quando possÃ­vel."""
    
    response = ollama.chat(
        model='llava:34b',
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image_path]
        }]
    )
    
    return response['message']['content']
```

---

## ğŸš€ Pipeline Proposto: IA + Processamento Tradicional

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Imagem Original â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. AnÃ¡lise IA (LLaVA)  â”‚ â† ExtraÃ§Ã£o de metadados
â”‚  - Fabricante           â”‚   Tipo de imagem
â”‚  - Modelo               â”‚   AvaliaÃ§Ã£o de qualidade
â”‚  - PotÃªncia             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ClassificaÃ§Ã£o       â”‚ â† Determina perfil
â”‚  - logo_simples         â”‚   de otimizaÃ§Ã£o
â”‚  - diagrama_tecnico     â”‚
â”‚  - produto_fotografia   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Processamento       â”‚ â† OpenCV + Pillow
â”‚  - Perfil especÃ­fico    â”‚   com parÃ¢metros
â”‚  - Quality 88-98        â”‚   ajustados por IA
â”‚  - Denoise 0-3          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Nomenclatura        â”‚ â† Nome padronizado
â”‚  FABRICANTE-CAT-MODELO  â”‚   gerado por IA
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. VersÃµes Responsivas â”‚ â† 4 tamanhos
â”‚  original/large/med/th  â”‚   (1200/800/400)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Script Integrado

```python
#!/usr/bin/env python3
"""
Pipeline Inteligente de Processamento de Imagens
Combina IA local (Ollama) + processamento tradicional
"""

import ollama
from PIL import Image
import cv2
import json


class AIImageProcessor:
    def __init__(self, model='llava:13b'):
        self.model = model
    
    def process_image(self, image_path, distributor='ODEX'):
        """Pipeline completo de processamento"""
        
        print(f'ğŸ¤– Analisando com IA: {image_path}')
        
        # 1. ExtraÃ§Ã£o de metadados por IA
        metadata = self.extract_metadata_ai(image_path)
        print(f'   Fabricante: {metadata.get("manufacturer")}')
        print(f'   Modelo: {metadata.get("model")}')
        print(f'   PotÃªncia: {metadata.get("power")}')
        
        # 2. ClassificaÃ§Ã£o de tipo
        image_type = self.classify_image_type(image_path)
        print(f'   Tipo detectado: {image_type}')
        
        # 3. AnÃ¡lise de qualidade
        quality = self.analyze_quality(image_path)
        print(f'   Qualidade: {quality["score"]}/10')
        
        # 4. Gerar nome padronizado
        filename = self.generate_standard_name(metadata, distributor)
        print(f'   Nome padronizado: {filename}')
        
        # 5. Selecionar perfil de otimizaÃ§Ã£o
        profile = self.select_optimization_profile(image_type, quality)
        print(f'   Perfil: quality={profile["quality"]}, denoise={profile["denoise"]}')
        
        # 6. Processar imagem
        output_path = self.optimize_image(image_path, filename, profile)
        
        return {
            'metadata': metadata,
            'type': image_type,
            'quality': quality,
            'filename': filename,
            'profile': profile,
            'output': output_path
        }
    
    def extract_metadata_ai(self, image_path):
        """Extrai metadados usando LLaVA"""
        
        prompt = """Extraia informaÃ§Ãµes desta imagem de produto solar.
        Retorne JSON: {"manufacturer": "...", "category": "...", "model": "...", "power": "..."}"""
        
        try:
            response = ollama.chat(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': prompt,
                    'images': [image_path]
                }]
            )
            
            return json.loads(response['message']['content'])
        except:
            return {}
    
    def classify_image_type(self, image_path):
        """Classifica tipo de imagem"""
        
        prompt = """Classifique esta imagem em UMA categoria:
        - logo_simples
        - diagrama_tecnico
        - produto_fotografia
        - produto_render
        Responda apenas a categoria."""
        
        try:
            response = ollama.chat(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': prompt,
                    'images': [image_path]
                }]
            )
            
            return response['message']['content'].strip()
        except:
            return 'produto_fotografia'  # fallback
    
    def analyze_quality(self, image_path):
        """Analisa qualidade da imagem"""
        
        prompt = """Avalie a qualidade desta imagem (1-10).
        Retorne JSON: {"score": 8, "problems": ["..."]}"""
        
        try:
            response = ollama.chat(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': prompt,
                    'images': [image_path]
                }]
            )
            
            return json.loads(response['message']['content'])
        except:
            return {'score': 7, 'problems': []}
    
    def generate_standard_name(self, metadata, distributor):
        """Gera nome padronizado"""
        
        parts = [
            metadata.get('manufacturer', 'UNKNOWN').upper(),
            metadata.get('category', 'PROD')[:3].upper(),
            metadata.get('model', '').upper(),
            metadata.get('power', '').upper(),
            distributor.upper()
        ]
        
        return '-'.join([p for p in parts if p])
    
    def select_optimization_profile(self, image_type, quality):
        """Seleciona perfil baseado em tipo e qualidade"""
        
        profiles = {
            'logo_simples': {'quality': 98, 'denoise': 0, 'sharpen': 0},
            'diagrama_tecnico': {'quality': 95, 'denoise': 1, 'sharpen': 0},
            'produto_fotografia': {'quality': 90, 'denoise': 2, 'sharpen': 0.5},
            'produto_render': {'quality': 88, 'denoise': 3, 'sharpen': 1.0}
        }
        
        profile = profiles.get(image_type, profiles['produto_fotografia'])
        
        # Ajustar baseado em qualidade
        if quality.get('score', 7) < 6:
            profile['denoise'] += 1
            profile['sharpen'] += 0.5
        
        return profile
    
    def optimize_image(self, input_path, filename, profile):
        """Otimiza imagem com perfil selecionado"""
        
        img = Image.open(input_path)
        
        # Processar com OpenCV se necessÃ¡rio
        if profile['denoise'] > 0 or profile['sharpen'] > 0:
            img_array = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            
            if profile['denoise'] > 0:
                img_array = cv2.fastNlMeansDenoisingColored(img_array, None, profile['denoise'] * 3, 10, 7, 21)
            
            if profile['sharpen'] > 0:
                kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) * profile['sharpen']
                img_array = cv2.filter2D(img_array, -1, kernel)
            
            img = Image.fromarray(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))
        
        # Salvar
        output_path = f'static/images-ai-processed/{filename}.webp'
        img.save(output_path, 'WEBP', quality=profile['quality'], method=6)
        
        return output_path


# Uso
processor = AIImageProcessor(model='llava:13b')
result = processor.process_image('static/images-catÃ¡logo_distribuidores/ODEX-INVERTERS/276954.jpg', 'ODEX')
```

---

## ğŸ“Š ComparaÃ§Ã£o de Modelos

| Modelo | Tamanho | VRAM | Velocidade | Qualidade | Recomendado Para |
|--------|---------|------|------------|-----------|------------------|
| **LLaVA 34B** | 34GB | 24GB | Lento (10s/img) | â­â­â­â­â­ | ProduÃ§Ã£o, anÃ¡lise detalhada |
| **LLaVA 13B** | 13GB | 8GB | MÃ©dio (3s/img) | â­â­â­â­ | **Recomendado** balanceado |
| **BakLLaVA 7B** | 7GB | 4GB | RÃ¡pido (1s/img) | â­â­â­ | Preview, triagem rÃ¡pida |
| **CogVLM 34B** | 34GB | 40GB | Lento (15s/img) | â­â­â­â­â­ | Melhor OCR, texto tÃ©cnico |
| **BLIP-2 6.7B** | 6.7GB | 16GB | RÃ¡pido (2s/img) | â­â­â­â­ | Captions, descriÃ§Ãµes |
| **Qwen-VL 9.6B** | 9.6GB | 16GB | MÃ©dio (4s/img) | â­â­â­â­ | Suporte PT-BR |

---

## ğŸ’¡ RecomendaÃ§Ã£o Final

### Setup Ideal para YSH Store

1. **Modelo Principal**: **LLaVA 13B** (Ollama)
   - Melhor custo-benefÃ­cio
   - Roda em GPU mainstream (RTX 3070+)
   - Qualidade suficiente para metadados

2. **Backup**: **BLIP-2** (HuggingFace)
   - Para geraÃ§Ã£o de descriÃ§Ãµes
   - Fallback quando Ollama indisponÃ­vel

3. **Pipeline**:

   ```
   Imagem â†’ LLaVA (metadados) â†’ Perfil â†’ OpenCV (processamento) â†’ WebP (4 tamanhos)
   ```

### PrÃ³ximos Passos

1. âœ… Instalar Ollama + LLaVA 13B
2. âœ… Criar script de teste com 10 imagens
3. âœ… Validar qualidade de extraÃ§Ã£o vs manual
4. âœ… Integrar com pipeline existente
5. âœ… Processar lote completo (278 imagens)

**Ãšltima atualizaÃ§Ã£o**: 13 de outubro de 2025  
**Status**: ğŸ¯ Pronto para ImplementaÃ§Ã£o
