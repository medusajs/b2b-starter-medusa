# üöÄ Guia de Otimiza√ß√£o do Workflow - Vision + Text Models

**Data**: 13 de outubro de 2025  
**Modelos**: Llama 3.2 Vision:11b + Gemma 3:4b/12b + GPT-OSS:20b  
**Objetivo**: Acelerar processamento de 25h ‚Üí 2-4h

---

## üìä An√°lise de Performance Atual

### Tempos Medidos (5 imagens teste)

| Etapa | Modelo | Tempo | % Total |
|-------|--------|-------|---------|
| **An√°lise Visual** | Llama 3.2 Vision:11b | 107s/img | 85% |
| **Normaliza√ß√£o** | Gemma 3:4b | 2-3s | 2% |
| **Enriquecimento** | Gemma 3:4b | 5-8s | 6% |
| **Valida√ß√£o** | Gemma 3:4b | 1-2s | 1% |
| **I/O e overhead** | - | 5-10s | 6% |
| **TOTAL** | - | **120-130s/produto** | 100% |

### Gargalo Identificado

**85% do tempo est√° na an√°lise visual com Llama Vision!**

```
Llama Vision (107s) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 85%
Gemma 3 (10s)       ‚ñà‚ñà‚ñà‚ñà‚ñà 8%
Overhead (10s)      ‚ñà‚ñà 7%
```

---

## üéØ Estrat√©gias de Acelera√ß√£o

### Estrat√©gia 1: Otimiza√ß√£o do Llama Vision (Cr√≠tico)

#### 1.1 Warmup do Modelo

**Problema**: Primeiras 3-4 imagens levam 130s, depois caem para 40s.

**Solu√ß√£o**: Pr√©-aquecer modelo antes do processamento.

```python
def warmup_vision_model(model: str, iterations: int = 3):
    """
    Aquece modelo com imagens dummy para atingir performance √≥tima
    Reduz tempo de 130s ‚Üí 40s nas primeiras imagens
    """
    print(f"üî• Aquecendo {model}...")
    
    # Usar imagem pequena e prompt simples
    dummy_prompt = "Descreva esta imagem em uma palavra."
    dummy_image = create_tiny_test_image()  # 100x100px
    
    warmup_times = []
    for i in range(iterations):
        start = time.time()
        ollama.chat(
            model=model,
            messages=[{
                'role': 'user',
                'content': dummy_prompt,
                'images': [dummy_image]
            }],
            options={'num_predict': 50}
        )
        elapsed = time.time() - start
        warmup_times.append(elapsed)
        print(f"   Warmup {i+1}/{iterations}: {elapsed:.1f}s")
    
    print(f"‚úÖ Modelo aquecido! ({warmup_times[-1]:.1f}s √∫ltima itera√ß√£o)\n")
```

**Ganho esperado**: -55% no tempo m√©dio (107s ‚Üí 48s)

#### 1.2 Redu√ß√£o Dr√°stica do Prompt

**Problema**: Prompt atual tem ~500 tokens, aumenta tempo de processamento.

**Solu√ß√£o**: Prompt minimalista com apenas o essencial.

```python
# ‚ùå ANTES (500 tokens)
prompt = """Voc√™ √© um especialista em produtos fotovoltaicos.

Analise esta imagem de produto e extraia TODOS os dados vis√≠veis:

{
  "manufacturer": "marca/logo vis√≠vel (ex: SAJ, Growatt, Canadian Solar)",
  "model": "c√≥digo/modelo exato vis√≠vel",
  "product_type": "inverter/panel/battery/stringbox/structure/other",
  "subtype": "gridtie/hybrid/offgrid/mono/poly/bifacial/N/A",
  "specifications": {
    "power_w": 0,
    "power_kw": 0.0,
    "voltage": "220V/380V/...",
    "current_a": 0,
    "phase": "mono/tri/N/A",
    "efficiency_percent": 0.0,
    "mppt_count": 0,
    "max_input_voltage": 0,
    "max_output_current": 0
  },
  "visible_text": "transcreva TODO texto leg√≠vel na imagem",
  "certifications": ["INMETRO", "IEC", "CE", etc],
  "image_quality": {
    "score": 0-10,
    "usable_for_catalog": true/false,
    "issues": ["listar problemas se houver"]
  }
}

IMPORTANTE: 
- Se n√£o conseguir ler algum dado, deixe como null ou 0
- Seja preciso nos n√∫meros e especifica√ß√µes
- Transcreva TODO texto vis√≠vel, mesmo que pequeno

Retorne APENAS o JSON, sem texto adicional."""

# ‚úÖ DEPOIS (120 tokens) - 75% menor
prompt = """JSON da imagem:
{"manufacturer":"","model":"","type":"inverter/panel","specs":{"kw":0,"voltage":"","mppt":0},"text":"","quality":0-10}

Apenas JSON v√°lido."""
```

**Ganho esperado**: -25% no tempo (48s ‚Üí 36s)

#### 1.3 Otimiza√ß√£o de Par√¢metros Ollama

```python
# ‚ùå ANTES
options = {
    'temperature': 0.1,
    'num_predict': 1500  # Gera at√© 1500 tokens!
}

# ‚úÖ DEPOIS
options = {
    'temperature': 0.0,      # Totalmente determin√≠stico
    'num_predict': 400,      # JSON minimalista ~300 tokens
    'top_k': 5,              # Apenas top 5 tokens
    'top_p': 0.85,           # Foca nas escolhas mais prov√°veis
    'repeat_penalty': 1.2,   # Evita repeti√ß√£o
    'num_ctx': 2048,         # Context window menor
    'num_gpu': 33            # Todas as camadas na GPU (se dispon√≠vel)
}
```

**Ganho esperado**: -15% no tempo (36s ‚Üí 30s)

#### 1.4 Compress√£o de Imagens

```python
def optimize_image_for_vision(image_path: Path, max_size: int = 1024) -> Path:
    """
    Redimensiona imagem mantendo qualidade para OCR
    Imagens menores = processamento mais r√°pido
    """
    from PIL import Image
    
    img = Image.open(image_path)
    
    # Se j√° √© pequena, retorna original
    if max(img.size) <= max_size:
        return image_path
    
    # Redimensionar mantendo aspect ratio
    img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
    
    # Salvar tempor√°rio
    temp_path = Path(f"/tmp/{image_path.stem}_optimized{image_path.suffix}")
    img.save(temp_path, quality=85, optimize=True)
    
    return temp_path
```

**Ganho esperado**: -10% no tempo (30s ‚Üí 27s)

---

### Estrat√©gia 2: Processamento Paralelo (Cr√≠tico)

#### 2.1 Multi-threading para I/O

```python
from concurrent.futures import ThreadPoolExecutor
import queue

def process_images_parallel(images: List[Path], model: str, workers: int = 3):
    """
    Processa m√∫ltiplas imagens em paralelo
    Reduz tempo total em ~60%
    """
    
    results = []
    
    # Pool de workers
    with ThreadPoolExecutor(max_workers=workers) as executor:
        # Submit todas as tarefas
        futures = {
            executor.submit(
                extract_metadata_with_vision, 
                img, 
                model
            ): img for img in images
        }
        
        # Coletar resultados conforme completam
        from concurrent.futures import as_completed
        for future in as_completed(futures):
            img = futures[future]
            try:
                result = future.result()
                results.append({
                    'file': img.name,
                    'metadata': result
                })
                print(f"‚úÖ {img.name}")
            except Exception as e:
                print(f"‚ùå {img.name}: {e}")
                results.append({
                    'file': img.name,
                    'error': str(e)
                })
    
    return results
```

**Limita√ß√£o**: Ollama executa modelos sequencialmente por padr√£o.

**Solu√ß√£o**: M√∫ltiplas inst√¢ncias Ollama ou usar GPU com batch.

**Ganho esperado**: 2-3x mais r√°pido com 3 workers (se infra permitir)

#### 2.2 Pipeline Ass√≠ncrono

```python
import asyncio

async def async_vision_analysis(image: Path, model: str):
    """An√°lise de vis√£o ass√≠ncrona"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None, 
        extract_metadata_with_vision, 
        image, 
        model
    )

async def async_text_processing(vision_result: Dict, model: str):
    """Processamento de texto ass√≠ncrono"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None,
        enrich_with_gemma3,
        vision_result,
        model
    )

async def process_product_pipeline(image: Path):
    """Pipeline completo ass√≠ncrono"""
    
    # Etapa 1: Vis√£o (lento)
    vision_task = async_vision_analysis(image, 'llama3.2-vision:11b')
    
    # Enquanto processa vis√£o, preparar pr√≥xima imagem
    vision_result = await vision_task
    
    # Etapa 2: Texto (r√°pido) - pode paralelizar
    text_tasks = [
        async_text_processing(vision_result, 'gemma3:4b'),
        async_validate_pvlib(vision_result),
        async_check_pricing(vision_result)
    ]
    
    results = await asyncio.gather(*text_tasks)
    
    return combine_results(vision_result, results)

async def process_batch_async(images: List[Path], batch_size: int = 5):
    """Processa lote com concorr√™ncia controlada"""
    
    semaphore = asyncio.Semaphore(batch_size)
    
    async def process_with_limit(img):
        async with semaphore:
            return await process_product_pipeline(img)
    
    tasks = [process_with_limit(img) for img in images]
    return await asyncio.gather(*tasks)
```

**Ganho esperado**: 40-50% mais r√°pido para lotes grandes

---

### Estrat√©gia 3: Cache Inteligente

#### 3.1 Cache de Resultados de Vis√£o

```python
import hashlib
from pathlib import Path

class VisionCache:
    """Cache persistente para resultados de an√°lise visual"""
    
    def __init__(self, cache_dir: Path):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.hits = 0
        self.misses = 0
    
    def get_cache_key(self, image_path: Path, model: str) -> str:
        """Gera chave √∫nica baseada em hash da imagem + modelo"""
        img_hash = hashlib.sha256(image_path.read_bytes()).hexdigest()
        return f"{model}_{img_hash}"
    
    def get(self, image_path: Path, model: str) -> Optional[Dict]:
        """Busca no cache"""
        key = self.get_cache_key(image_path, model)
        cache_file = self.cache_dir / f"{key}.json"
        
        if cache_file.exists():
            self.hits += 1
            return json.loads(cache_file.read_text())
        
        self.misses += 1
        return None
    
    def set(self, image_path: Path, model: str, result: Dict):
        """Salva no cache"""
        key = self.get_cache_key(image_path, model)
        cache_file = self.cache_dir / f"{key}.json"
        cache_file.write_text(json.dumps(result, indent=2))
    
    def stats(self) -> Dict:
        """Estat√≠sticas do cache"""
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0
        return {
            'hits': self.hits,
            'misses': self.misses,
            'hit_rate': f"{hit_rate:.1f}%",
            'total_cached': len(list(self.cache_dir.glob('*.json')))
        }

# Uso
cache = VisionCache(Path('cache/vision'))

def extract_with_cache(image: Path, model: str):
    # Tentar cache primeiro
    cached = cache.get(image, model)
    if cached:
        print(f"‚úÖ Cache hit: {image.name}")
        return cached
    
    # Processar e cachear
    print(f"üîÑ Processando: {image.name}")
    result = extract_metadata_with_vision(image, model)
    cache.set(image, model, result)
    
    return result
```

**Ganho esperado**: Re-processamento instant√¢neo (economiza 100% em imagens repetidas)

#### 3.2 Cache de Modelos em Mem√≥ria

```python
class ModelPool:
    """Pool de modelos pr√©-carregados"""
    
    def __init__(self):
        self.models = {}
        self.lock = threading.Lock()
    
    def get_or_load(self, model_name: str):
        """Retorna modelo carregado ou carrega se necess√°rio"""
        with self.lock:
            if model_name not in self.models:
                print(f"üì• Carregando {model_name}...")
                # For√ßa carregamento fazendo query dummy
                ollama.generate(model=model_name, prompt="OK")
                self.models[model_name] = True
                print(f"‚úÖ {model_name} carregado na RAM")
            
            return model_name
    
    def preload_all(self, model_names: List[str]):
        """Pr√©-carrega todos os modelos"""
        print("üî• Pr√©-carregando modelos...")
        for model in model_names:
            self.get_or_load(model)
        print("‚úÖ Todos os modelos prontos!\n")

# Uso
pool = ModelPool()
pool.preload_all([
    'llama3.2-vision:11b',
    'gemma3:4b',
    'gpt-oss:20b'
])
```

---

### Estrat√©gia 4: Workflow Inteligente

#### 4.1 Decis√£o Din√¢mica de Modelos

```python
def select_best_model_for_image(image_path: Path) -> str:
    """
    Seleciona modelo mais adequado baseado em caracter√≠sticas da imagem
    """
    from PIL import Image
    
    img = Image.open(image_path)
    width, height = img.size
    file_size = image_path.stat().st_size
    
    # Imagens grandes e complexas ‚Üí modelo mais poderoso
    if width > 2000 or height > 2000 or file_size > 5_000_000:
        return 'llama3.2-vision:90b'  # Melhor qualidade
    
    # Imagens m√©dias ‚Üí modelo balanceado
    elif width > 1000 or file_size > 1_000_000:
        return 'llama3.2-vision:11b'  # Recomendado
    
    # Imagens pequenas e simples ‚Üí modelo r√°pido
    else:
        return 'gemma3:4b'  # Se tiver capacidade de vis√£o
```

#### 4.2 Pipeline H√≠brido Otimizado

```python
def optimized_hybrid_pipeline(image_path: Path) -> Dict:
    """
    Pipeline otimizado com paraleliza√ß√£o estrat√©gica
    """
    
    # ETAPA 1: Vis√£o (gargalo) - executar primeiro
    print(f"üîç An√°lise visual...")
    vision_start = time.time()
    vision_result = extract_with_cache(
        optimize_image_for_vision(image_path),
        'llama3.2-vision:11b'
    )
    vision_time = time.time() - vision_start
    print(f"   ‚úÖ Vis√£o completa: {vision_time:.1f}s")
    
    # ETAPA 2: Processamento paralelo de texto
    print(f"üìù Enriquecimento paralelo...")
    text_start = time.time()
    
    with ThreadPoolExecutor(max_workers=3) as executor:
        # Executar em paralelo
        future_normalize = executor.submit(
            normalize_with_gemma3, 
            vision_result, 
            'gemma3:4b'
        )
        
        future_enrich = executor.submit(
            enrich_with_gemma3,
            vision_result,
            'gemma3:4b'
        )
        
        future_validate = executor.submit(
            validate_with_pvlib,
            vision_result
        )
        
        # Aguardar conclus√£o
        normalized = future_normalize.result()
        enriched = future_enrich.result()
        validated = future_validate.result()
    
    text_time = time.time() - text_start
    print(f"   ‚úÖ Texto completo: {text_time:.1f}s")
    
    # ETAPA 3: Combina√ß√£o final
    final_result = {
        'vision': vision_result,
        'normalized': normalized,
        'enriched': enriched,
        'validated': validated,
        'processing_times': {
            'vision': vision_time,
            'text': text_time,
            'total': vision_time + text_time
        }
    }
    
    print(f"‚úÖ Total: {final_result['processing_times']['total']:.1f}s\n")
    
    return final_result
```

---

### Estrat√©gia 5: Acelera√ß√£o por GPU

#### 5.1 Configura√ß√£o Otimizada

```bash
# Configurar Ollama para usar GPU otimamente
export OLLAMA_GPU_LAYERS=33        # Todas as camadas
export OLLAMA_NUM_GPU=1             # Usar 1 GPU
export OLLAMA_MAX_LOADED_MODELS=3   # Manter 3 modelos na VRAM
export OLLAMA_FLASH_ATTENTION=1     # Flash attention (mais r√°pido)
```

#### 5.2 Verifica√ß√£o de GPU

```python
def check_gpu_status():
    """Verifica se GPU est√° sendo usada"""
    try:
        result = subprocess.run(
            ['ollama', 'ps'],
            capture_output=True,
            text=True
        )
        
        print("üìä Status Ollama:")
        print(result.stdout)
        
        # Verificar NVIDIA
        gpu_result = subprocess.run(
            ['nvidia-smi', '--query-gpu=name,memory.used,memory.total', '--format=csv'],
            capture_output=True,
            text=True
        )
        
        print("\nüéÆ Status GPU:")
        print(gpu_result.stdout)
        
    except Exception as e:
        print(f"‚ö†Ô∏è  N√£o foi poss√≠vel verificar GPU: {e}")
```

**Ganho esperado com GPU**: 2-3x mais r√°pido (30s ‚Üí 10-15s)

---

## üìä Comparativo de Performance

### Cen√°rios de Otimiza√ß√£o

| Otimiza√ß√£o | Tempo/Img | Ganho | Cumulative |
|-----------|-----------|-------|------------|
| **Baseline** (atual) | 107s | - | 107s |
| + Warmup | 48s | -55% | 48s |
| + Prompt otimizado | 36s | -25% | 36s |
| + Par√¢metros | 30s | -17% | 30s |
| + Compress√£o imagem | 27s | -10% | 27s |
| + Cache (2¬™ execu√ß√£o) | 0.1s | -99.6% | 0.1s |
| + GPU | 10s | -63% | 10s |
| + Paraleliza√ß√£o 3x | 3.3s | -67% | 3.3s |

### Tempo Total para Cat√°logo (854 produtos)

| Cen√°rio | Tempo/Produto | Tempo Total | Vs Baseline |
|---------|---------------|-------------|-------------|
| **Atual** | 120s | 28.5h | - |
| **Otimizado** | 35s | 8.3h | **-71%** ‚ö°‚ö° |
| **+ GPU** | 15s | 3.6h | **-87%** üöÄ |
| **+ Paralelo 3x** | 5s | 1.2h | **-96%** üî• |

---

## üé¨ Implementa√ß√£o por Fases

### Fase 1: Quick Wins (Hoje - 2h)

**Implementar**:
- ‚úÖ Warmup do modelo
- ‚úÖ Prompt minimalista
- ‚úÖ Par√¢metros otimizados
- ‚úÖ Cache b√°sico

**Script**: `process-images-optimized-v1.py`

**Ganho esperado**: 107s ‚Üí 35s (-67%)

```bash
python scripts/process-images-optimized-v1.py --test 10
```

### Fase 2: Paralleliza√ß√£o (Amanh√£ - 4h)

**Implementar**:
- ‚úÖ ThreadPoolExecutor
- ‚úÖ Pipeline ass√≠ncrono
- ‚úÖ Processamento em lote

**Script**: `process-images-parallel-v2.py`

**Ganho esperado**: 35s ‚Üí 12s (-66% adicional)

```bash
python scripts/process-images-parallel-v2.py --workers 3 --batch 50
```

### Fase 3: GPU Acceleration (Esta Semana - 1 dia)

**Implementar**:
- ‚úÖ Configura√ß√£o GPU otimizada
- ‚úÖ Monitoramento de VRAM
- ‚úÖ Batch processing na GPU

**Ganho esperado**: 12s ‚Üí 4-5s (-60% adicional)

```bash
OLLAMA_GPU_LAYERS=33 python scripts/process-images-gpu-v3.py --all
```

### Fase 4: Produ√ß√£o (Quando validado)

**Implementar**:
- ‚úÖ Script completo integrado
- ‚úÖ Monitoramento em tempo real
- ‚úÖ Recupera√ß√£o de erros
- ‚úÖ Relat√≥rios autom√°ticos

**Meta final**: **854 produtos em 1-2 horas**

```bash
python scripts/process-full-catalog.py \
  --optimize \
  --gpu \
  --parallel 3 \
  --cache \
  --output data/enriched_catalog
```

---

## üìà M√©tricas de Sucesso

### Objetivos T√©cnicos

- ‚úÖ Tempo m√©dio < 10s por produto
- ‚úÖ Throughput > 300 produtos/hora
- ‚úÖ Taxa de sucesso > 98%
- ‚úÖ Hit rate de cache > 50% em re-runs
- ‚úÖ Uso de GPU > 80%

### Objetivos de Neg√≥cio

- ‚úÖ Cat√°logo completo < 3 horas
- ‚úÖ Custo operacional: R$ 0 (tudo local)
- ‚úÖ Qualidade de dados > 95%
- ‚úÖ Re-processamento < 30min

---

## üí° Conclus√£o

### Situa√ß√£o Atual
- ‚è±Ô∏è 120s/produto
- üïê 28.5 horas para cat√°logo completo
- üêå Gargalo: Llama Vision (85% do tempo)

### Ap√≥s Otimiza√ß√µes
- ‚è±Ô∏è **5-10s/produto** (-95%)
- üïê **1-2 horas para cat√°logo** (-96%)
- üöÄ **Throughput: 300-500 produtos/hora**

### Pr√≥xima A√ß√£o

```bash
# Testar otimiza√ß√µes com 10 imagens
python scripts/create-optimized-processor.py
python scripts/process-images-optimized-v1.py --test 10 --verbose
```

---

**Autor**: YSH AI Team  
**Data**: 13/10/2025  
**Vers√£o**: 1.0  
**Status**: Ready for Implementation
